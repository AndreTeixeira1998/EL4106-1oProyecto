{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Reshape\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000, 21, 21, 4)\n",
      "(40000, 24, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "samples= 5\n",
    "tipo = 3    # np.random.randint(4)\n",
    "index_image = np.random.randint(100000)  \n",
    "\n",
    "\n",
    "# ========== EXTRACCIÓN DE DATOS ==============\n",
    "archivo = open('./dataset/HiTS2013_100k_samples(4_channels)_images_labels.pkl',\"rb\")\n",
    "example_dict= pickle.load(archivo)\n",
    "print(example_dict['labels'].shape)\n",
    "print(example_dict['images'].shape)\n",
    "\n",
    "L=example_dict['labels'].shape[0] #numero total de imagenes\n",
    "\n",
    "input_images=example_dict['images'][:40000, :, :, tipo]\n",
    "input_images=np.expand_dims(input_images, axis=-1)\n",
    "\n",
    "#padded\n",
    "input_images=np.pad(input_images, ((0,0),(2,1), (2,1), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "print(input_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "def normalize(processed):\n",
    "    ####### calculate global mean and standard deviation\n",
    "    mean, std = processed.mean(), processed.std()\n",
    "    #print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "    ####### global standardization of pixels\n",
    "    processed = (processed - mean) / std\n",
    "    ####### clip pixel values to [-1,1]\n",
    "    processed = np.clip(processed, -1.0, 1.0)\n",
    "    ####### shift from [-1,1] to [0,1] with 0.5 mean\n",
    "    processed = (processed + 1.0) / 2.0\n",
    "    #print('after normalization')\n",
    "    #print('Valor máximo :', processed.max())\n",
    "    #print('Valor mínimo :', processed.min())\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess 3D to 2D\n",
    "\n",
    "def preprocessar_2d(ximg):\n",
    "\n",
    "    print(ximg.shape)\n",
    "    x= np.squeeze(ximg, axis=2)  \n",
    "    print('---->', x.shape)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape de mapas de oclusion: (40000, 21, 21, 1)\n",
      "(21, 21, 1)\n",
      "----> (21, 21)\n",
      "Nº labels:  40000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAGgElEQVR4nO3dTYhVdRjH8XOrWQyIggslqGWLjKQ2SZsorFYWFL1QFBhEuCgqCiEiuIIFLiNaCEJCRYW9odGiNwpsUUSIhC0SCkLICMEUJDROizai4/CcmXvu/d07n8/SefifMy9fDsjDuYO2bRsgz2WTvgFgYeKEUOKEUOKEUOKEUFcs9sXhYDAV/5U7N+kbGKFFfyEXmB/xXNM0zbni3JkRz/Xh7ASv3cWwbQcL/bsnJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4TqspAyVn1s/cR+s+fp8n2v7eHMquPFuS4/8+p2UlUf3/c4t448OSGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCHUottV1fWnaXmRUtW0vDCsep9dXvA1a7/LURvn34YnJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4SKfedVl02VUW9tdNmoqf4AV4/4vKZpmms7zFZVP7LvRHGuy0u7Rv2Cr2nnyQmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhFt0Wm5aXPY16he7eDtdef3VxcFdxbnP92vvWbSnN3f/TJ/VDX6mNHXunNlddB2ya0e+STvs6oCcnhBInhBInhBInhBInhBInhBInhBInhBInhIp9wVcfqi/uWv9G/cxXtz5Rmnvmtt21Ax/+pX7x5u3i3P7yiatO/1WaO7V9XWnu7K3lSzd7T9bmThXPsyEE9EKcEEqcEEqcEEqcEEqcEEqcEEqcEEqcEGpFbQjdVJx7aesL5TN3Dp4uTg7LZ47ejvLk6VW1ucGhtjTXfjgoX3tj8f1JPxbP6/L+okSenBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBqRa3vbbizNrdzd/Fz8Jqmmexa3gTdMCyN3de+WT7y/WseLc0d7vIOtKJqCON8aZgnJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RaURtCzUPFuWd7vYsV5YN7HqkPP1fbEJrfVjuujz/uLmcud5vIkxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCzcSG0Fxxrr27OPjYwaXeChf6+L3y6B8frSnNzW87udS7mSqenBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBqJtb3qo6uvao4+X2v97Gy/FyePNDcVZrb2LxVmjtavnI/lhuXJyeEEieEEieEEieEEieEEieEEieEEieEEieEmokNofni3JFmQ3Hy76XeChepbf00TdM8+O/NpbnvlnorU8aTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0LNxPreuuLc5c25Xu+Di13Vri7Prn7ybGnuxFJvZhHVv4xxBuPJCaHECaHECaHECaHECaHECaHECaHECaHECaFmYkNorji35YevaoO3f1m/+BfD+uws2TMsjf2+d1A+cv/rtbljxfP62Acb546ZJyeEEieEEieEEieEEieEEieEEieEEieEEieEGvuGUHWbp4vyB/Y9Xxt77evHy9d+6sY9tcFDw/KZE/XusDTWXlfb/Pn8+vqlf6uPlnT54058u5QnJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QatG17yS8OB4NLf/E8fazkdVm9ql5/bXFu66b6tdtPa3O3rP2sNHfwmzvqFy/unG3fvKN85K59w9LckQdq5x0oX7mu+vuufaDg/ya5vvdi2y64C+nJCaHECaHECaHECaHECaHECaHECaHECaHECaEW3RB6ubgh1EUfbxSrbozMF+fWdbj2+uLcpjW1ubkrO1z8n9rY4V/rR35bnDtenJvk9ljiS7sWYkMIpow4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTYPwKwqo/tjuo3e6LDmdXZYydrc2eLc03TNGeKc3/Wj+z03p1JnNeXxPv05IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQY1/fm4aXLnW5x+raV3XNr4+fT+Jq2nJUv58uLxfr42MFl8uTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0ItuiE0a5slp4pzXdamRr3RM2s/8z708bGCfVx7ub9LT04IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IFfv5nF2M+oVPXrJFAk9OCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCDVo23bS9wAswJMTQokTQokTQokTQokTQokTQv0Hwn6xhTf+LGMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "imagem=30000      #Choose image to visualize\n",
    "\n",
    "\n",
    "archivo_occluded = open('./dataset/OCmaps_F.pkl',\"rb\")\n",
    "OCmaps= pickle.load(archivo_occluded)\n",
    "\n",
    "\n",
    "\n",
    "OCimg=OCmaps[\"image\"]\n",
    "\n",
    "print(\"shape de mapas de oclusion:\", OCimg.shape)\n",
    "input_shape=OCimg[imagem].shape\n",
    "OCimg=preprocessar_2d(OCimg[imagem])\n",
    "\n",
    "\n",
    "labelOcc=OCmaps[\"label\"]\n",
    "labelOcc=labelOcc[:OCmaps[\"image\"].shape[0]]\n",
    "\n",
    "n_labels=  labelOcc.shape[0]\n",
    "\n",
    "#print(\"labels shape: \", labelOcc.shape)\n",
    "print(\"Nº labels: \", n_labels)\n",
    "\n",
    "\n",
    "plt.imshow(OCimg, cmap='jet')                #[2:19, 2:19])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 24, 24, 1)\n",
      "input shape:  (24, 24, 1)\n",
      "(24, 24, 1)\n",
      "----> (24, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#padding images\n",
    "\n",
    "occ_img_padded=np.pad(OCmaps[\"image\"], ((0,0),(2,1), (2,1), (0, 0)), 'constant')\n",
    "print(occ_img_padded.shape)\n",
    "input_shape=occ_img_padded[imagem].shape\n",
    "print('input shape: ', input_shape)\n",
    "\n",
    "plt.imshow(preprocessar_2d(occ_img_padded[imagem]), cmap='jet')                #[2:19, 2:19])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ modelo Autoencoder en Keras #################\n",
    "\n",
    "\n",
    "def autoencoder_test():\n",
    "\n",
    "    model = Sequential()\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), padding='same', strides=(1, 1),\n",
    "                     input_shape=input_shape))\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #max-pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))              \n",
    "    #max-pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "#\n",
    "\n",
    "    model.add(Reshape((6,6,1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))    \n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))  \n",
    "    #upsamp\n",
    "    model.add(UpSampling2D(size=(2, 2))) \n",
    "    \n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), padding='same', strides=(1, 1)))\n",
    " \n",
    "    #upsamp\n",
    "    model.add(UpSampling2D(size=(2, 2))) \n",
    "    \n",
    "    #conv\n",
    "    model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same', strides=(1, 1)))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(classifier, dim, mode=True):\n",
    "    \n",
    "    weights = classifier.layers[0].get_weights()\n",
    "    print(weights[0].shape)\n",
    "    print(weights[1].shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), padding='same', strides=(1, 1),\n",
    "                     input_shape=input_shape, trainable=False))\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', strides=(1, 1), trainable=mode))\n",
    "    #max-pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1), trainable=mode))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1), trainable=mode))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1), trainable=mode))              \n",
    "    #max-pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(dim, activation='softmax'))\n",
    "    \n",
    "    if mode==False:\n",
    "        model.layers[0].set_weights(classifier.layers[0].get_weights())\n",
    "        model.layers[1].set_weights(classifier.layers[1].get_weights())\n",
    "        model.layers[3].set_weights(classifier.layers[3].get_weights())\n",
    "        model.layers[4].set_weights(classifier.layers[4].get_weights())\n",
    "        model.layers[5].set_weights(classifier.layers[5].get_weights())\n",
    "        \n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(model):\n",
    "\n",
    "    \n",
    "\n",
    "    model.add(Reshape((6,6,1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))    \n",
    "    #conv\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', strides=(1, 1)))  \n",
    "    #upsamp\n",
    "    model.add(UpSampling2D(size=(2, 2))) \n",
    "    \n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', strides=(1, 1)))\n",
    "    #conv\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), padding='same', strides=(1, 1)))\n",
    " \n",
    "    #upsamp\n",
    "    model.add(UpSampling2D(size=(2, 2))) \n",
    "    \n",
    "    #conv\n",
    "    model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same', strides=(1, 1)))\n",
    "    \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(model, verbose=0):\n",
    "    \n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    if verbose==1:\n",
    "        for i,layer in enumerate(model.layers):\n",
    "            print(i,layer.name)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3652: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:166: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "(4, 4, 1, 32)\n",
      "(32,)\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1937: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "0 conv2d_1\n",
      "1 conv2d_2\n",
      "2 max_pooling2d_1\n",
      "3 conv2d_3\n",
      "4 conv2d_4\n",
      "5 conv2d_5\n",
      "6 max_pooling2d_2\n",
      "7 flatten_1\n",
      "8 dense_1\n",
      "9 reshape_1\n",
      "10 conv2d_6\n",
      "11 conv2d_7\n",
      "12 conv2d_8\n",
      "13 up_sampling2d_1\n",
      "14 conv2d_9\n",
      "15 conv2d_10\n",
      "16 up_sampling2d_2\n",
      "17 conv2d_11\n"
     ]
    }
   ],
   "source": [
    "encoder=encoder(load_model('supernova_class.model'), 36, False) #aqui modelo \n",
    "model=autoencoder(decoder(encoder), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                82980     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 6, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 64)          640       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 32)        16416     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 1)         289       \n",
      "=================================================================\n",
      "Total params: 294,789\n",
      "Trainable params: 192,645\n",
      "Non-trainable params: 102,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:714: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/endredra/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:717: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 79s 2ms/step - loss: 0.3769\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 75s 2ms/step - loss: 0.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd921ceb630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenar\n",
    "epocas=2\n",
    "batch=10\n",
    "x_train=occ_img_padded\n",
    "\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "#print('input shape: ', x_train.shape)\n",
    "\n",
    "model.fit(input_images, x_train,\n",
    "                epochs=epocas,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                callbacks=[TensorBoard(log_dir='./tmp/autoencoder')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    \n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7858), started 5:24:16 ago. (Use '!kill 7858' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd8fb19a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./tmp/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 25s 632us/step\n"
     ]
    }
   ],
   "source": [
    "decoded_imgs = model.predict(input_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006584045325639199\n"
     ]
    }
   ],
   "source": [
    "print(mse(x_train[imagem], decoded_imgs[imagem]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 1)\n",
      "----> (24, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test=8001\n",
    "\n",
    "plt.imshow(preprocessar_2d(decoded_imgs[test]), cmap='jet')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 1)\n",
      "----> (24, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocessar_2d(occ_img_padded[test]), cmap='jet')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003462150119107915\n"
     ]
    }
   ],
   "source": [
    "print(mse(x_train[test], decoded_imgs[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 1)\n",
      "----> (24, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocessar_2d(input_images[test]), cmap='jet')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=model.input, outputs=model.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 420us/step\n"
     ]
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(input_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 24, 24, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                82980     \n",
      "=================================================================\n",
      "Total params: 185,124\n",
      "Trainable params: 82,980\n",
      "Non-trainable params: 102,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 36)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1549579e-08 2.8421185e-08 3.3283801e-08 2.2588102e-08 2.0272651e-08\n",
      " 1.4618731e-08 1.2903372e-08 9.9480081e-01 7.8380022e-09 2.4854589e-08\n",
      " 2.4360615e-08 1.8501321e-08 5.1976033e-03 2.0585576e-08 2.5829789e-09\n",
      " 6.8692052e-10 1.8914941e-08 4.5521517e-08 5.1523340e-08 3.6250576e-08\n",
      " 1.2326817e-08 1.4300088e-07 6.9200119e-08 1.3184705e-07 7.8189984e-08\n",
      " 2.2336101e-08 6.4345023e-09 1.8152576e-08 3.0245931e-07 2.1847472e-07\n",
      " 3.6259014e-08 1.2445911e-08 3.4006753e-08 3.5574793e-08 9.1583161e-08\n",
      " 3.2316734e-08]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_imgs[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
