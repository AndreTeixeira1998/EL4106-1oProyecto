{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion Map Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimage\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 3    #change type of image (0 to 3)\n",
    "\n",
    "\n",
    "# ========== EXTRACCIÓN DE DATOS ==============\n",
    "archivo = open('./dataset/HiTS2013_100k_samples(4_channels)_images_labels.pkl',\"rb\")\n",
    "example_dict= pickle.load(archivo)\n",
    "print('Dimension of labels: N=',example_dict['labels'].shape[0])\n",
    "print('Dimension of images:',example_dict['images'].shape)\n",
    "\n",
    "L=example_dict['labels'].shape[0] #numero total de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_train=1   #how much do you want to train?\n",
    "\n",
    "percentage= int(percentage_train*L)\n",
    "xx = example_dict['images'][:, :, :, tipo]\n",
    "yy= example_dict['labels']\n",
    "print('Dimension of images to train:',xx[:percentage].shape)\n",
    "print('Dimension of images to test:',xx[percentage:].shape)\n",
    "print('Number of images to train: ', yy[:percentage].shape[0])\n",
    "print('Number of images to test: ',yy[percentage:].shape[0])\n",
    "\n",
    "#database to train\n",
    "x_train=xx[:percentage]\n",
    "y_train=yy[:percentage]\n",
    "\n",
    "#database to test\n",
    "x_test=xx[percentage:]\n",
    "y_test=yy[percentage:]\n",
    "\n",
    "#input shape para las redes convolucionales\n",
    "input_shape1=x_test.shape[1]\n",
    "input_shape2=x_test.shape[2]\n",
    "print('\\n\\ninput_shape (2D): ' , input_shape1, 'x', input_shape2)\n",
    "\n",
    "input_shape = (input_shape1, input_shape2, 1)\n",
    "print('\\n\\ninput_shape (3D): ' , input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images.\n",
    "r_x_train= np.expand_dims(x_train, axis=3)\n",
    "r_x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "print('r_x_train', r_x_train.shape)\n",
    "print('r_x_test', r_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some useful functions\n",
    "\n",
    "def to_3_axis(im_2d):\n",
    "    im_3d = np.expand_dims(im_2d, axis=3)\n",
    "    return im_3d\n",
    "\n",
    "def to_4_axis(im_3d):\n",
    "    im_4d = np.expand_dims(im_3d, axis=0)\n",
    "    return im_4d    \n",
    "\n",
    "def d2_to_d4(d2):\n",
    "    d3=np.expand_dims(d2, axis=0)\n",
    "    d4=np.expand_dims(d3, axis=-1)\n",
    "    return d4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "def normalize(processed):\n",
    "    ####### calculate global mean and standard deviation\n",
    "    mean, std = processed.mean(), processed.std()\n",
    "    #print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "    ####### global standardization of pixels\n",
    "    processed = (processed - mean) / std\n",
    "    ####### clip pixel values to [-1,1]\n",
    "    processed = np.clip(processed, -1.0, 1.0)\n",
    "    ####### shift from [-1,1] to [0,1] with 0.5 mean\n",
    "    processed = (processed + 1.0) / 2.0\n",
    "    #print('after normalization')\n",
    "    #print('Valor máximo :', processed.max())\n",
    "    #print('Valor mínimo :', processed.min())\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occlusion Generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcclusionGenerator(object):\n",
    "     \n",
    "    def __init__(self, img, boxsize=10, step=10, prepocess=True):\n",
    "        ''' Initializations '''\n",
    "        self.img = img\n",
    "        self.boxsize = boxsize\n",
    "        self.step = step \n",
    "        self.i = 0\n",
    "        self.j = 0\n",
    "    \n",
    "\n",
    "    def flow(self):\n",
    "        ''' Return a single occluded image and its location '''\n",
    "        if self.i + self.boxsize > self.img.shape[0]:\n",
    "            return None, None, None\n",
    "        \n",
    "        #print('test shape', self.img.shape)\n",
    "        \n",
    "        retImg = np.copy(self.img)\n",
    "        retImg[self.i:self.i+self.boxsize, self.j:self.j+self.boxsize] = 0.0 \n",
    "\n",
    "        old_i = deepcopy(self.i) \n",
    "        old_j = deepcopy(self.j)\n",
    "        \n",
    "        # update indices\n",
    "        self.j = self.j + self.step\n",
    "        if self.j+self.boxsize>self.img.shape[1]: #reached end\n",
    "            self.j = 0 # reset j\n",
    "            self.i = self.i + self.step # go to next row\n",
    "        \n",
    "        return retImg, old_i, old_j\n",
    "\n",
    "    def gen_minibatch(self, batchsize=10):\n",
    "        ''' Returns a minibatch of images of size <=batchsize '''\n",
    "        \n",
    "        # list of occluded images\n",
    "        occ_imlist = []\n",
    "        locations = []\n",
    "        for i in range(batchsize):\n",
    "            occimg, i, j = self.flow()\n",
    "            if occimg is not None:\n",
    "                occ_imlist.append(occimg)\n",
    "                locations.append([i,j])\n",
    "\n",
    "        if len(occ_imlist)==0: # no data\n",
    "            return None,None\n",
    "        else:\n",
    "            # convert list to numpy array\n",
    "            \n",
    "            return normalize(np.array(occ_imlist)), locations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess to 2D and gets copy\n",
    "\n",
    "def preprocessar(ximg):\n",
    "    #image of (21,21)\n",
    "    x = np.zeros((21, 21))\n",
    "    print(ximg.shape)\n",
    "    rimg= np.stack((ximg,)*3, axis=-1)\n",
    "    x[:,:]= ximg[:,:] \n",
    "    print('---->', x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "#preprocess 3D to 2D\n",
    "\n",
    "def preprocessar_2d(ximg):\n",
    "\n",
    "    print(ximg.shape)\n",
    "    x= np.squeeze(ximg, axis=2)  \n",
    "    print('---->', x.shape)\n",
    "\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing out the occlusion generator class\n",
    "x=preprocessar(x_train[3])\n",
    "\n",
    "occ = OcclusionGenerator(x, 5, 1, False)\n",
    "occList = []\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "for i in range(100):\n",
    "    occList.append(occ.flow()[0])\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(occList[i+80], cmap='viridis'); plt.axis(\"off\")\n",
    "plt.show()\n",
    "#print(occList[i].shape)\n",
    "del occ, x ,occList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a list of heatmaps and merges them into one single heatmap\n",
    "def post_process(heatmap):\n",
    "\n",
    "    # postprocessing\n",
    "    total = heatmap[0]\n",
    "    for val in heatmap[1:]:\n",
    "        total = total + val\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### This is the meat of the program. It generates the heatmap for the given image location ####\n",
    "\n",
    "def gen_heatmap(fileloc, label, boxsize, step, verbose=True, savetodisk=False, batch=10, index=3):\n",
    "\n",
    "    # load up image \n",
    "\n",
    "    img=preprocessar_2d(fileloc[index])\n",
    "    if verbose:\n",
    "        plt.imshow(img); plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    r_img= fileloc[index]\n",
    "    \n",
    "    # classify image (w/o occlusions)   \n",
    "\n",
    "    model = load_model('super_nova_class.model')\n",
    "\n",
    "    img_pred=to_4_axis(r_img)\n",
    "    preds = model.predict(img_pred)\n",
    "    correct_class_index = np.argmax(preds)\n",
    "\n",
    "    # load correct label \n",
    "\n",
    "    correct_class_label = label[index]\n",
    "    if verbose:\n",
    "        print ('\\n\\n\\ncorrect_class_label:', correct_class_label, '\\n\\n\\n') \n",
    "\n",
    "    # generate occluded images and location of mask\n",
    "    occ = OcclusionGenerator(img, boxsize, step, True)\n",
    "\n",
    "    # scores of occluded image\n",
    "    heatmap = []\n",
    "    index = 0\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        # get minibatch of data\n",
    "        x, locations = occ.gen_minibatch(batchsize=batch)\n",
    "\n",
    "        if x is not None:\n",
    "\n",
    "            #predict \n",
    "            op = model.predict(np.expand_dims(x, axis=-1))\n",
    "\n",
    "            #unpack prediction values \n",
    "            for i in range(x.shape[0]):\n",
    "                score = op[i][correct_class_index]\n",
    "                r,c = locations[i] \n",
    "                scoremap = np.zeros((21,21))\n",
    "                scoremap[r : r+occ.boxsize, c : c+occ.boxsize] = score\n",
    "                heatmap.append(scoremap)\n",
    "\n",
    "            if verbose:\n",
    "                print ('..minibatch completed')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if savetodisk:\n",
    "        #save heatmap to disk \n",
    "        \n",
    "        f = open(\"heatmap\", 'wb')\n",
    "        pickle.dump(heatmap, f)\n",
    "        f.close()\n",
    "\n",
    "    return heatmap, correct_class_index, correct_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the program on image\n",
    "index_=95\n",
    "\n",
    "heatmapList, index, label = gen_heatmap(r_x_train, y_train ,  3, 1, True, False, batch=10, index=index_)\n",
    "processed   = post_process(heatmapList)\n",
    "processed = normalize(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "img=x_train[index_]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[2:19, 2:19]); plt.axis(\"off\")\n",
    "plt.title(\"Original image ---- Pred: \"+ str(label) )\n",
    "plt.subplot(122)\n",
    "plt.imshow(processed[2:19, 2:19])\n",
    "plt.title(\"Occlusion Map: \")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('       ESTADISTICAS Processed      \\n')\n",
    "print('Valor máximo :', processed.max())\n",
    "print('Valor mínimo :', processed.min())\n",
    "print('Valor promedio :', processed.mean())\n",
    "print('Valor varianza :', processed.var())\n",
    "print('Valor desviación standar :', processed.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
